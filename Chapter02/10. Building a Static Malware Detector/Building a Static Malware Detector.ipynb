{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정적 악성코드 탐지기 구축\n",
    "- PE헤더에서 추출한 특성 + N-그램에서 나온 특성 모두 사용\n",
    "- 샘플을 특성화 한 후 특성을 벡터로 만들고, 이를 함께 모은 다음, 분류기를 훈련하고 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 열거한 후, 레이블 지정\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "directories_with_labels = [(\"Benign PE Samples\", 0), (\"Malicious PE Samples\", 1)]\n",
    "list_of_samples = []\n",
    "labels = []\n",
    "for dataset_path, label in directories_with_labels:\n",
    "    samples = [f for f in listdir(dataset_path)]\n",
    "    for sample in samples:\n",
    "        file_path = os.path.join(dataset_path, sample)\n",
    "        list_of_samples.append(file_path)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 층화 훈련-테스트 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples_train, samples_test, labels_train, labels_test = train_test_split(\n",
    "    list_of_samples, labels, test_size=0.3, stratify=labels, random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전에 사용했던 함수 재사용\n",
    "import collections\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pefile\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Reads in the binary sequence of a binary file.\"\"\"\n",
    "    with open(file_path, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def byte_sequence_to_Ngrams(byte_sequence, N):\n",
    "    \"\"\"Creates a list of N-grams from a byte sequence.\"\"\"\n",
    "    Ngrams = ngrams(byte_sequence, N)\n",
    "    return list(Ngrams)\n",
    "\n",
    "\n",
    "def binary_file_to_Ngram_counts(file, N):\n",
    "    \"\"\"Takes a binary file and outputs the N-grams counts of its binary sequence.\"\"\"\n",
    "    filebyte_sequence = read_file(file)\n",
    "    file_Ngrams = byte_sequence_to_Ngrams(filebyte_sequence, N)\n",
    "    return collections.Counter(file_Ngrams)\n",
    "\n",
    "\n",
    "def get_NGram_features_from_sample(sample, K1_most_frequent_Ngrams_list):\n",
    "    \"\"\"Takes a sample and produces a feature vector.\n",
    "    The features are the counts of the K1 N-grams we've selected.\n",
    "    \"\"\"\n",
    "    K1 = len(K1_most_frequent_Ngrams_list)\n",
    "    feature_vector = K1 * [0]\n",
    "    file_Ngrams = binary_file_to_Ngram_counts(sample, N)\n",
    "    for i in range(K1):\n",
    "        feature_vector[i] = file_Ngrams[K1_most_frequent_Ngrams_list[i]]\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def preprocess_imports(list_of_DLLs):\n",
    "    \"\"\"Normalize the naming of the imports of a PE file.\"\"\"\n",
    "    temp = [x.decode().split(\".\")[0].lower() for x in list_of_DLLs]\n",
    "    return \" \".join(temp)\n",
    "\n",
    "\n",
    "def get_imports(pe):\n",
    "    \"\"\"Get a list of the imports of a PE file.\"\"\"\n",
    "    list_of_imports = []\n",
    "    for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "        list_of_imports.append(entry.dll)\n",
    "    return preprocess_imports(list_of_imports)\n",
    "\n",
    "\n",
    "def get_section_names(pe):\n",
    "    \"\"\"Gets a list of section names from a PE file.\"\"\"\n",
    "    list_of_section_names = []\n",
    "    for sec in pe.sections:\n",
    "        normalized_name = sec.Name.decode().replace(\"\\x00\", \"\").lower()\n",
    "        list_of_section_names.append(normalized_name)\n",
    "    return \"\".join(list_of_section_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 빈도수가 높은 2-그램 100개를 특성으로 선택\n",
    "N = 2\n",
    "Ngram_counts_all = collections.Counter([])\n",
    "for sample in samples_train:\n",
    "    Ngram_counts_all += binary_file_to_Ngram_counts(sample, N)\n",
    "K1 = 100\n",
    "K1_most_frequent_Ngrams = Ngram_counts_all.most_common(K1)\n",
    "K1_most_frequent_Ngrams_list = [x[0] for x in K1_most_frequent_Ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign PE Samples\\iisrstas.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\InspectVhdDialog6.2.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\lpr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\iissetup.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsmgmt.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\evntwin.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\CCG.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hcsdiag.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvsirdpclient.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\lpq.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvc.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvsimgr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\AppVStreamingUX.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Benign PE Samples\\bash.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsamain.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\LogCollector.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\malware.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Benign PE Samples\\dcdiag.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvsirpcd.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsdbutil.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dpnsvr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsacls.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\ADSchemaAnalyzer.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\iisreset.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\wirelesskeyview.exe:\n",
      "'utf-8' codec can't decode byte 0xff in position 1: invalid start byte\n",
      "Benign PE Samples\\csvde.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\ldifde.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\appcmd.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\BootExpCfg.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\adamuninstall.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\inetinfo.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# 훈련 과정에서 각 샘플의 N-그램 개수와 섹션 이름, 들여온 것들, 섹션의 개수를 추출하고 구문 분석할 수 없는 PE헤더를 가진 샘플은 건너뛰기\n",
    "imports_corpus_train = []\n",
    "num_sections_train = []\n",
    "section_names_train = []\n",
    "Ngram_features_list_train = []\n",
    "y_train = []\n",
    "for i in range(len(samples_train)):\n",
    "    sample = samples_train[i]\n",
    "    try:\n",
    "        NGram_features = get_NGram_features_from_sample(\n",
    "            sample, K1_most_frequent_Ngrams_list\n",
    "        )\n",
    "        pe = pefile.PE(sample)\n",
    "        imports = get_imports(pe)\n",
    "        n_sections = len(pe.sections)\n",
    "        sec_names = get_section_names(pe)\n",
    "        imports_corpus_train.append(imports)\n",
    "        num_sections_train.append(n_sections)\n",
    "        section_names_train.append(sec_names)\n",
    "        Ngram_features_list_train.append(NGram_features)\n",
    "        y_train.append(labels_train[i])\n",
    "    except Exception as e:\n",
    "        print(sample + \":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF(단어 빈도와 역문서 빈도) 와 hashingVectorizer를 사용하여 2개의 텍스트 특성, import한 것과 섹션 이름을 숫자 형식으로 변환\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imports_featurizer = Pipeline(\n",
    "    [\n",
    "        (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
    "    ]\n",
    ")\n",
    "section_names_featurizer = Pipeline(\n",
    "    [\n",
    "        (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
    "    ]\n",
    ")\n",
    "imports_corpus_train_transformed = imports_featurizer.fit_transform(\n",
    "    imports_corpus_train\n",
    ")\n",
    "section_names_train_transformed = section_names_featurizer.fit_transform(\n",
    "    section_names_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화된 특성을 하나의 배열로 만듦(다른 특성을 하나의 큰 희소 scipy 배열로 병합)\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "X_train = hstack(\n",
    "    [\n",
    "        Ngram_features_list_train,\n",
    "        imports_corpus_train_transformed,\n",
    "        section_names_train_transformed,\n",
    "        csr_matrix(num_sections_train).transpose(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에 대해 랜덤 포레스트 분류기를 훈련\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 데이터에 대한 랜덤 포레스트 분류기 점수\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'utf-8' codec can't decode byte 0xd2 in position 6: invalid continuation byte\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\findstr.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋의 특성 수집한 다음, 훈련 데이터셋에 대해 수행한 것 반복\n",
    "imports_corpus_test = []\n",
    "num_sections_test = []\n",
    "section_names_test = []\n",
    "Ngram_features_list_test = []\n",
    "y_test = []\n",
    "for i in range(len(samples_test)):\n",
    "    file = samples_test[i]\n",
    "    try:\n",
    "        NGram_features = get_NGram_features_from_sample(\n",
    "            sample, K1_most_frequent_Ngrams_list\n",
    "        )\n",
    "        pe = pefile.PE(file)\n",
    "        imports = get_imports(pe)\n",
    "        n_sections = len(pe.sections)\n",
    "        sec_names = get_section_names(pe)\n",
    "        imports_corpus_test.append(imports)\n",
    "        num_sections_test.append(n_sections)\n",
    "        section_names_test.append(sec_names)\n",
    "        Ngram_features_list_test.append(NGram_features)\n",
    "        y_test.append(labels_test[i])\n",
    "    except Exception as e:\n",
    "        print(sample + \":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 훈련한 변환기를 적용해 텍스트 특성을 벡터로 만든 다음, 남아 있는 테스트 데이터셋으로 분류기 테스트\n",
    "imports_corpus_test_transformed = imports_featurizer.transform(imports_corpus_test)\n",
    "section_names_test_transformed = section_names_featurizer.transform(section_names_test)\n",
    "X_test = hstack(\n",
    "    [\n",
    "        Ngram_features_list_test,\n",
    "        imports_corpus_test_transformed,\n",
    "        section_names_test_transformed,\n",
    "        csr_matrix(num_sections_test).transpose(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859649122807017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 세트에 대한 분류기 점수\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
